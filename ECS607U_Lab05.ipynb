{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ed-w-ds/Leetcode-Submits/blob/main/ECS607U_Lab05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opUJRrimoSfo"
      },
      "source": [
        "# Lab session 5: Classification and Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BvfYNFKoSfq"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "The aim of this lab (Lab session 5) is for students to get experience with **Classification** and **Clustering**, both covered in lecture 6, by using common Python libraries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91N-pqHAoSft"
      },
      "source": [
        "## Classification\n",
        "\n",
        "In order to present functionalities for data classification and clustering in Python, we use the [MNIST handwritten digits dataset](http://yann.lecun.com/exdb/mnist/) as part of a working example.\n",
        "\n",
        "The dataset can be accessed from [Keras](https://keras.io/api/datasets/mnist/) (a high-level, open-source Python library that helps users create data mining/machine and deep learning models).\n",
        "\n",
        "In the snippet below, ``X`` is a matrix (numpy array) where each row corresponds to an observation and each column corresponds to a feature. Each observation is the result of *flattening* a 28 x 28 grayscale image of a handwritten digit into a vector. The list ``y`` (numpy array) contains the class (a digit from 0 to 9) corresponding to each observation (row) in the matrix ``X``.\n",
        "\n",
        "For the sake of this tutorial, we select only the first 2000 observations (rows) from the original MNIST training dataset to expedite computations.\n",
        "\n",
        "It is possible to use the ``matplotlib`` function ``imshow`` to visualise any observation by reshaping it appropriately. You may change the index ``i`` to select an observation for visualisation.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuring the appearance of ``seaborn`` graphics in this notebook\n",
        "%config InlineBackend.figure_formats = set(['retina'])\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "\n",
        "#loading the dataset\n",
        "(X, y), (_, _) = mnist.load_data()\n",
        "\n",
        "# Subsampling\n",
        "sample_size = 2000\n",
        "X, y = X[:sample_size], y[:sample_size]\n",
        "X = np.reshape(X, (sample_size, 28*28))\n",
        "\n",
        "i = 12\n",
        "plt.imshow(X[i].reshape(28, 28), cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "plt.show()\n",
        "print('Observation index: {0}. Class: {1}.'.format(i, y[i]))"
      ],
      "metadata": {
        "id": "3I8QGnGdVQ63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "43914ca6-c90b-4041-f903-c455a0b1200c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 417,
              "height": 413
            }
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observation index: 12. Class: 3.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOP0Z62foSfv"
      },
      "source": [
        "The library ``sklearn`` implements all the learning algorithms that we covered during the lectures. Each algorithm is implemented by a class that provides a standard interface.\n",
        "\n",
        "The class ``KNeighborsClassifier`` implements a k-nearest neighbour classification algorithm. The number of neighbours is specified by the constructor parameter ``n_neighbors``.\n",
        "\n",
        "The method ``KNeighborsClassifier.fit`` is responsible for learning a classifier for a dataset represented by an observation matrix and a class array. This is precisely how our data is represented.\n",
        "\n",
        "The method ``KNeighborsClassifier.score`` computes the accuracy of a classifier on a specific dataset. This method must be called after ``KNeighborsClassifier.fit``.\n",
        "\n",
        "As we have seen, a one-nearest neighbour classifier always predicts the correct class for any observation that already exists in a dataset (as long as there are no equal observations with different classes), which is why we obtain 100% accuracy on the training set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_r1mctJoSfw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2184c330-d93a-4cdc-e874-374f3e594eea"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=1)\n",
        "knn.fit(X, y)\n",
        "print('Training dataset accuracy: {0}.'.format(knn.score(X, y)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset accuracy: 1.0.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPxqSYP4oSfw"
      },
      "source": [
        "In order to evaluate the capacity of a k-nearest neighbour classifier to assign unseen observations to correct classes, it is necessary to split the original dataset into a training dataset and a test dataset.\n",
        "\n",
        "The ``sklearn`` function ``train_test_split`` can be used for this purpose. This function selects a fraction of the observations (``test_size``) to compose the test set. The parameter ``random_state`` allows reproducibility by fixing the seed used by this (pseudo)random selection procedure.\n",
        "\n",
        "The function ``train_test_split`` returns a training observation matrix, a test observation matrix, a training class array, and a test class array. From now on, all classifiers are trained without access to the test dataset.\n",
        "\n",
        "The method ``KNeighborsClassifier.fit`` can be used to fit a k-nearest neighbour classifier to the training dataset. Naturally, the accuracy of the one-nearest neighbour classifier on the training set remains 100%. The accuracy on the test set, however, is a better estimate of the performance of the classifier on unseen data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4run65xSoSfx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "165bc734-7e67-426d-ef88-102045c03540"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=1)\n",
        "knn.fit(X_train, y_train)\n",
        "print('Training dataset accuracy: {0}.'.format(knn.score(X_train, y_train)))\n",
        "print('Test dataset accuracy: {0}.'.format(knn.score(X_test, y_test)))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset accuracy: 1.0.\n",
            "Test dataset accuracy: 0.8925.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lm92SlgoSfx"
      },
      "source": [
        "After a ``KNeighborsClassifier`` is fit, the method ``KNeighborsClassifier.predict`` can be used to predict the classes for a list of observations.\n",
        "\n",
        "For example, we may use this method to predict the class for every observation in the test dataset. This allows obtaining the indices of the observations that are classified incorrectly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I47mfrtRoSfy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d78776b1-7017-4779-efb9-b719e1f54ad8"
      },
      "source": [
        "y_pred = knn.predict(X_test)\n",
        "mistakes = np.nonzero(y_pred != y_test)[0]\n",
        "\n",
        "print('Indices of misclassified observations:')\n",
        "print(mistakes)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indices of misclassified observations:\n",
            "[ 28  32  39  42  55  61  68  82  83  85  90  92  94  97  98  99 110 124\n",
            " 128 132 148 152 154 162 174 197 199 202 211 215 218 223 228 232 248 271\n",
            " 280 303 308 322 350 362 372]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3q9NKQAaoSfy"
      },
      "source": [
        "We can use the ``matplotlib`` function ``imshow`` to visualise a misclassified observation. You may change the index for ``mistakes`` in order to select an observation for visualisation (requires running all cells above, because ``y_pred`` is modified later). Note how some misclassifications are understandable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SRnYZXRoSfz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "e321e2f4-fe38-4d12-93e4-ec9b76be527b"
      },
      "source": [
        "i = mistakes[16]\n",
        "plt.imshow(X_test[i].reshape(28, 28), cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "plt.show()\n",
        "print('Observation index: {0}. Class: {1}. Prediction: {2}.'.format(i, y_test[i], y_pred[i]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 417,
              "height": 413
            }
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observation index: 110. Class: 8. Prediction: 5.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkO2w2QloSfz"
      },
      "source": [
        "Some datasets need to be preprocessed before a learning algorithm can be applied. The training dataset must be preprocessed without access to the test dataset, otherwise the resulting test accuracy after preprocessing is likely to overestimate the accuracy on unseen data.\n",
        "\n",
        "The function ``make_pipeline`` allows chaining a sequence of preprocessing operations (such as individually standardizing each feature, which is accomplished by the class ``StandardScaler``) before a learning algorithm is applied. This function returns a ``Pipeline`` object that can be used to fit, predict, and score, just as any other classification algorithm in ``sklearn``. A ``Pipeline`` preprocesses incoming data appropriately before making predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIBcVR9ToSfz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "5e411955-65a0-4e27-8651-66b88d9d09ec"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "knn_pipe = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=1))\n",
        "\n",
        "knn_pipe.fit(X_train, y_train)\n",
        "print('Test dataset accuracy: {0}.'.format(knn_pipe.score(X_test, y_test)))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [1300, 1600]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-edec66daca7f>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mknn_pipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mknn_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test dataset accuracy: {0}.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m                 \u001b[0mlast_step_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrouted_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlast_step_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fit\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mfitted\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnearest\u001b[0m \u001b[0mneighbors\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \"\"\"\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"requires_y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNeighborsBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m                 X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    476\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    648\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1318\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_numeric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1300, 1600]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJ1Asa_uoSf0"
      },
      "source": [
        "Consider the task of selecting the best possible number of neighbours k (a hyperparameter) for the k-nearest neighbour classification algorithm.\n",
        "\n",
        "As we have seen, a hyperparameter should not be chosen based on its performance on the test dataset. In that case, there would be no data left to enable a reliable estimate of how well this choice generalizes to unseen data. After all, this choice would have been based on the test dataset.\n",
        "\n",
        "Therefore there exist two options: either the whole dataset is split into a training, a validation and a testing set, or k-fold cross validation is performed."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "</br>"
      ],
      "metadata": {
        "id": "29jOl89Xfo6x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Option 1*: **Exercise**\n",
        "\n",
        "Split the whole dataset into training, validation and testing sets with ratios 65-15-20% and then perform  k-nearest neighbour with k = 5 and 15. Choose the best value for k according to the performance on the validation set."
      ],
      "metadata": {
        "id": "TNswLeBffATB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1875)  # 0.1875 * 0.8 = 0.15\n",
        "\n",
        "k = 5\n",
        "\n",
        "knn_pipe = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=k))\n",
        "\n",
        "knn_pipe.fit(X_train, Y_train)\n",
        "\n",
        "val_accuracy = knn_pipe.score(X_val, Y_val)\n",
        "print('Validation dataset accuracy: {0}.'.format(val_accuracy))\n",
        "\n",
        "test_accuracy = knn_pipe.score(X_test, Y_test)\n",
        "print('Test dataset accuracy: {0}.'.format(test_accuracy))\n",
        "\n"
      ],
      "metadata": {
        "id": "yUa8A3HYfmez",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "151a32ec-e9b4-443e-aece-e10867f11b83"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation dataset accuracy: 0.85.\n",
            "Test dataset accuracy: 0.8275.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "</br>"
      ],
      "metadata": {
        "id": "CfQDN9QwfqP_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Option 2: The function ``cross_validate`` conducts K-fold cross validation using a specified training dataset. Cross-validation involves splitting a training dataset into K folds of equal size (this K and the k in k-nn should not be confused; they are different). Each fold is used as a validation set (on which the performance is computed) when the remaining folds are used as an effective training set (where a classifier is learned). The parameter ``cv`` controls the number of folds K. The function returns a dictionary with statistics that include a list of accuracies (i.e. performance metric) that can be accessed by the keyword ``'test_score'``.\n",
        "\n",
        "After a hyperparameter is selected by cross-validation, it can be used to fit a classifier to the entire training dataset, which can then be evaluated in the test dataset.\n",
        "\n",
        "Once again, if any step leading to model selection is based on the resulting performance on the test dataset, the resulting test accuracy is likely to overestimate the accuracy of the model on unseen data."
      ],
      "metadata": {
        "id": "53SzsxyEeiM2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeBHf_OeoSf1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3027b4e8-4c17-45d5-939e-6dbd57b6e4c7"
      },
      "source": [
        "knn_5 = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_15 = KNeighborsClassifier(n_neighbors=15)\n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "# Note that the data was already implicitly shuffled by train_test_split\n",
        "result_5 = cross_validate(knn_5, X_train, y_train, cv=5)\n",
        "result_15 = cross_validate(knn_15, X_train, y_train, cv=5)\n",
        "\n",
        "print('Average accuracy across folds (k = 5): {0}.'.format(result_5['test_score'].mean()))\n",
        "print('Average accuracy across folds (k = 15): {0}.'.format(result_15['test_score'].mean()))\n",
        "\n",
        "knn_5.fit(X_train, y_train)\n",
        "print('Test dataset accuracy (k = 5): {0}.'.format(knn_5.score(X_test, y_test)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average accuracy across folds (k = 5): 0.884375.\n",
            "Average accuracy across folds (k = 15): 0.8700000000000001.\n",
            "Test dataset accuracy (k = 5): 0.875.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhERgJSDoSf1"
      },
      "source": [
        "The class ``GridSearchCV`` offers a convenient way to choose hyperparameters based on cross-validation. Its constructor receives a classification algorithm object (such as a ``KNeighborsClassifier`` object) and a dictionary that maps hyperparameter names to lists of values that should be considered. Once the method ``GridSearchCV.fit`` is called, each possible combination of hyperparameters from each of the lists is evaluated using cross-validation. The best hyperparameter setting is then used to fit a classifier to the training dataset. After fitting, the ``GridSearchCV`` object can be used to predict and score just as any other classification algorithm in ``sklearn``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59I1PvY2oSf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ad715fb-71f0-4899-eec3-49f571616f20"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameters = {'n_neighbors': [1, 3, 5, 7, 9]}\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "knn_cv = GridSearchCV(knn, parameters, cv=5)\n",
        "knn_cv.fit(X_train, y_train)\n",
        "\n",
        "print('Best hyperparameter setting: {0}.'.format(knn_cv.best_estimator_))\n",
        "print('Average accuracy across folds of best hyperparameter setting: {0}.'.format(knn_cv.best_score_))\n",
        "print('Test dataset accuracy of best hyperparameter setting: {0}.'.format(knn_cv.score(X_test, y_test)))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameter setting: KNeighborsClassifier(n_neighbors=1).\n",
            "Average accuracy across folds of best hyperparameter setting: 0.899375.\n",
            "Test dataset accuracy of best hyperparameter setting: 0.8925.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ifj8XHloSf2"
      },
      "source": [
        "Accuracy is not the only classification performance metric available on ``sklearn``. For instance, it is possible to compute the precision and recall for each class by considering the remaining classes as beloging to a single (negative) class. This is accomplished by the function ``precision_recall_fscore_support``.\n",
        "\n",
        "The function ``confusion_matrix`` creates a confusion matrix given a class/label array and a prediction array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZzK_ybKoSf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "acb06305-39cd-43fc-fc27-e7c7ced7a611"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_pred = knn_cv.predict(X_test)\n",
        "\n",
        "precision, recall, _, _ = precision_recall_fscore_support(y_test, y_pred)\n",
        "print('Precision for each class: {0}.'.format(precision))\n",
        "print('Recall for each class: {0}.\\n'.format(recall))\n",
        "\n",
        "df = pd.DataFrame.from_records(confusion_matrix(y_test, y_pred))\n",
        "print('Confusion matrix:')\n",
        "display(df)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision for each class: [1.         0.8        0.975      0.975      0.85106383 0.82051282\n",
            " 0.95121951 0.89473684 0.87096774 0.80555556].\n",
            "Recall for each class: [0.97435897 1.         0.84782609 0.88636364 0.85106383 0.88888889\n",
            " 0.92857143 0.87179487 0.84375    0.82857143].\n",
            "\n",
            "Confusion matrix:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    0   1   2   3   4   5   6   7   8   9\n",
              "0  38   0   0   0   0   0   1   0   0   0\n",
              "1   0  40   0   0   0   0   0   0   0   0\n",
              "2   0   3  39   0   0   2   0   1   1   0\n",
              "3   0   1   1  39   0   1   0   1   0   1\n",
              "4   0   3   0   0  40   0   0   1   0   3\n",
              "5   0   0   0   1   0  32   1   0   2   0\n",
              "6   0   1   0   0   1   1  39   0   0   0\n",
              "7   0   0   0   0   2   1   0  34   0   2\n",
              "8   0   2   0   0   0   2   0   0  27   1\n",
              "9   0   0   0   0   4   0   0   1   1  29"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9aae167f-0357-4414-9265-4f3114de7fb3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9aae167f-0357-4414-9265-4f3114de7fb3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9aae167f-0357-4414-9265-4f3114de7fb3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9aae167f-0357-4414-9265-4f3114de7fb3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e59d1bce-5c57-4113-9b78-1a5d535fad6c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e59d1bce-5c57-4113-9b78-1a5d535fad6c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e59d1bce-5c57-4113-9b78-1a5d535fad6c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_86731e67-a7ba-454a-a313-27f5404f7cd6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_86731e67-a7ba-454a-a313-27f5404f7cd6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 0,\n        \"max\": 38,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          38\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 0,\n        \"max\": 40,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          40,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 0,\n        \"max\": 39,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          39\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 0,\n        \"max\": 39,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          39\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 4,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 0,\n        \"max\": 40,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          40,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 5,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 0,\n        \"max\": 32,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          32\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 6,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 0,\n        \"max\": 39,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 7,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 0,\n        \"max\": 34,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 8,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 0,\n        \"max\": 27,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          27\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 9,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 0,\n        \"max\": 29,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          29\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kejHZvqtoSf3"
      },
      "source": [
        "As mentioned before, ``sklearn`` implements learning algorithms covered during the lectures:  [support vector machines](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html), [artificial neural networks](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html), [decision trees](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html), and [random forest classifiers](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).\n",
        "\n",
        "The interface provided by each of these learning algorithms is analogous to the interface provided by the k-nearest neighbour classification algorithm that we have used so far.\n",
        "\n",
        "For instance, in order to train a random forest classifier composed of 100 decision trees, an object of the class ``RandomForestClassifier`` can be constructed with ``n_estimators`` set to 100. This object can be used to fit the training dataset and compute the accuracy on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNoTJBItoSf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24b328d9-394c-4a5d-92fb-97e231cf9434"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rfc = RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "rfc.fit(X_train, y_train)\n",
        "print(rfc.score(X_test, y_test))\n",
        "print('Test dataset accuracy (random forest classifier): {0}.'.format(rfc.score(X_test, y_test)))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8925\n",
            "Test dataset accuracy (random forest classifier): 0.8925.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "</br>"
      ],
      "metadata": {
        "id": "mrsOpM__rekf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Exercise##\n",
        "\n",
        "Train a support vector machine classifier using the same training dataset used in the previous sections and compute its accuracy on the corresponding test dataset. You can use the default hyperparameters for the class SVC from sklearn.svm"
      ],
      "metadata": {
        "id": "uHnZK8ZGqzh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# insert code here\n"
      ],
      "metadata": {
        "id": "4GJw77--3RGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "</br>"
      ],
      "metadata": {
        "id": "H1smir3rrgbx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Exercise##\n",
        "\n",
        "\n",
        "Using the same training dataset used in the previous sections, employ ``GridSearchCV`` to find the best hyperparameter settings based on 5-fold cross-validation for a ``RandomForestClassifier``. Consider ``n_estimators`` $ \\in \\{ 50, 100, 200\\}$ and ``max_features`` $ \\in \\{0.1, 0.25\\}$. Use the default values for the remaining hyperparameters. Compute the accuracy of the best model on the corresponding test dataset."
      ],
      "metadata": {
        "id": "9gcT0yGR2_EP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# insert code here"
      ],
      "metadata": {
        "id": "fdB2oTI33Sha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "</br>"
      ],
      "metadata": {
        "id": "MaXtgWsM3PLP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQe9zr1EoSf3"
      },
      "source": [
        "## Clustering\n",
        "\n",
        "The clustering algorithms implemented by ``sklearn`` have an interface that is similar to the interface for the classification algorithms.\n",
        "\n",
        "The class ``KMeans`` implements the k-means clustering algorithm. The number of clusters ``n_clusters`` is a parameter for the constructor of this class.\n",
        "\n",
        "The method ``KMeans.fit_predict`` is equivalent to a call to ``KMeans.fit`` followed by a call to ``KMeans.predict``, which is responsible for attributing each observation to a cluster. After the clustering is computed by a call to ``KMeans.fit``, the sum of squared errors of the clustering is available as a class variable named ``inertia_``.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOd-hVO0oSf4"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "kmeans = KMeans(n_clusters=10, random_state=0)\n",
        "y_pred = kmeans.fit_predict(X)\n",
        "\n",
        "print('Sum of squared errors (k = 10): {0}.'.format(kmeans.inertia_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLtJPXlvoSf4"
      },
      "source": [
        "In order to compare the quality of clusterings of the same dataset for different numbers of clusters, it is possible to employ both sums of squared errors and silhouette coefficients."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "mjxY-EyqoSf4"
      },
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "max_k = 15\n",
        "\n",
        "# Sum of squared errors for each k\n",
        "sses = []\n",
        "\n",
        "# Silhouette coefficient for each k\n",
        "silhouettes = []\n",
        "\n",
        "for k in range(2, max_k + 1):\n",
        "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
        "    y_pred = kmeans.fit_predict(X)\n",
        "\n",
        "    sses.append(kmeans.inertia_)\n",
        "    silhouettes.append(silhouette_score(X, y_pred))\n",
        "\n",
        "# Plotting sums of squared errors\n",
        "df = pd.DataFrame({'sum of squared errors': sses, 'number of clusters': list(range(2, max_k + 1))})\n",
        "sns.lineplot(x='number of clusters', y='sum of squared errors', data=df)\n",
        "plt.xticks(df['number of clusters'])\n",
        "plt.show()\n",
        "\n",
        "# Plotting silhouette coefficients\n",
        "df = pd.DataFrame({'silhouette coefficient': silhouettes, 'number of clusters': list(range(2, max_k + 1))})\n",
        "sns.lineplot(x='number of clusters', y='silhouette coefficient', data=df)\n",
        "plt.xticks(df['number of clusters'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0VjCYNYoSf4"
      },
      "source": [
        "A projection computed using t-stochastic neighbor embedding (implemented by the class ``TSNE``) can be used to visualise the results of clustering.\n",
        "\n",
        "Recall that dimensionality reduction attemps to represent a dataset by a projection such that each point in the projection corresponds to an observation. The t-stochastic neighbor embedding algorithm attempts to preserve neighbourhoods of the dataset in the corresponding projection.\n",
        "\n",
        "It is important to note that a projection is not, in general, a reliable representation of a dataset. Therefore, care must be taken before deriving conclusions from such visualisations.\n",
        "\n",
        "Note that the numbers assigned to clusters are unlikely to match the numbers assigned to classes. Therefore, only relative colouring is important in the plots shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiUlOCF-oSf5"
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Computing a projection using t-stochastic neighbour embedding\n",
        "embedding = TSNE(n_components=2, perplexity=50, random_state=0)\n",
        "Xp = embedding.fit_transform(X)\n",
        "\n",
        "# Plotting projection colored by classes\n",
        "df_projection = pd.DataFrame({'x': Xp[:, 0], 'y': Xp[:, 1], 'class': y})\n",
        "sns.scatterplot(x='x', y='y', hue='class', palette=sns.color_palette(), data=df_projection)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "plt.show()\n",
        "\n",
        "kmeans = KMeans(n_clusters=10, random_state=0)\n",
        "y_pred = kmeans.fit_predict(X)\n",
        "\n",
        "# Plotting projection colored by clusters\n",
        "df_projection = pd.DataFrame({'x': Xp[:, 0], 'y': Xp[:, 1], 'cluster': y_pred})\n",
        "sns.scatterplot(x='x', y='y', hue='cluster', palette=sns.color_palette(), data=df_projection)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}